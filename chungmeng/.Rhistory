## ignore "NA" as they will be considered as missing when converting categorical to factors
unique(house_train$MSZoning)
factorLevel$MSZoning
factorLevel$MSZoning[2] <- "C (all)"
unique(house_train$Neighborhood)
factorLevel$Neighborhood
factorLevel$Neighborhood[13] <- "NAmes"
unique(house_train$BldgType)
factorLevel$BldgType
factorLevel$BldgType[c(2,3,5)] <- c("2fmCon","Duplex","Twnhs")
unique(house_train$Exterior2nd)
factorLevel$Exterior2nd
factorLevel$Exterior2nd[c(17,6,3)] <- c("Wd Shng","CmentBd","Brk Cmn")
## Get levels that only appear in the dataset
for (varname in names(factorLevel)) {
factorLevel[[varname]] <- intersect(factorLevel[[varname]],
unique(house_train[[varname]]))
}
## Re-run the previous cell to double check
## convert column datatype to numeric / factor
## On training dataset
for (varname in names(house_train)[-1]) {
if (varname %in% names(factorLevel)) {
house_train[[varname]] <- factor(house_train[[varname]],
levels = factorLevel[[varname]])
} else {
house_train[[varname]] <- as.numeric(house_train[[varname]])
}
}
## On testing dataset
for (varname in names(house_test)[-1]) {
if (varname %in% names(factorLevel)) {
house_test[[varname]] <- factor(house_test[[varname]],
levels = factorLevel[[varname]])
} else {
house_test[[varname]] <- as.numeric(house_test[[varname]])
}
}
#Convert OverallQual from Factor to Numeric
house_train$OverallQual=as.numeric(as.character(house_train$OverallQual))
house_test$OverallQual=as.numeric(as.character(house_test$OverallQual))
names(house_train)
shortlis=c('MSZoning','Neighborhood','HouseStyle','OverallQual','YearBuilt',
'ExterQual','Foundation','BsmtQual','X1stFlrSF','X2ndFlrSF','GrLivArea',
'FullBath','TotRmsAbvGrd','GarageFinish','GarageCars','GarageArea',
'PavedDrive','SaleType','SaleCondition')
house_train=house_train[,c(shortlis,'SalePrice')]
house_test=house_test[,shortlis]
View(house_train)
View(house_test)
house_train$Id <- NULL
rownames(house_test) <- house_test$Id
house_test$Id <- NULL
save(house_train, house_test, file = "./house_loaded.RData")
load('house_loaded.RData')
plot(house_train$OverallQual,house_train$SalePrice)
ggplot(house_train, aes(x=OverallQual,y=SalePrice))+geom_violin()+geom_boxplot(width=.1)
ggplot(house_train, aes(x=as.factor(OverallQual),y=SalePrice))+geom_violin()+geom_boxplot(width=.1)
ggplot(house_train, aes(x=as.factor(OverallQual),y=log(SalePrice)))+geom_violin()+geom_boxplot(width=.1)
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(dplyr)
library(tidyr)
setwd("C:/Users/cmlim/Dropbox/NYC Data Science/Class/Machine Learning Project/chungmeng")
house_train <- read.csv("../data/train.csv",
header = TRUE,
na.strings = "",
stringsAsFactors = FALSE)
## load test data
house_test <- read.csv("../data/test.csv",
header = TRUE,
na.strings = "",
stringsAsFactors = FALSE)
## get levels of categorical features from data description
factorLevel <- list()
conn <- file("../data/data_description.txt", open="r")
f <-readLines(conn)
for (line in f){
if(!grepl("^[[:blank:]]", line) & grepl(": ", line)) {
col_name <<- trimws(gsub(":.*", "", line))
} else {
level <- trimws(gsub("\t.*", "", line))
if (level != "") {
factorLevel[[col_name]] <- c(factorLevel[[col_name]], level)
}
}
}
close(conn)
print(factorLevel[1:6])
## check if levels in description cover unique data values
for (varname in names(factorLevel)) {
levelDiff <- setdiff(unique(house_train[[varname]]),
factorLevel[[varname]])
if(length(levelDiff)) {
print(paste(varname,
paste(levelDiff, collapse = ", "),
sep = ": "))
}
}
## fix those levels that don't match with data
## ignore "NA" as they will be considered as missing when converting categorical to factors
unique(house_train$MSZoning)
factorLevel$MSZoning
factorLevel$MSZoning[2] <- "C (all)"
unique(house_train$Neighborhood)
factorLevel$Neighborhood
factorLevel$Neighborhood[13] <- "NAmes"
unique(house_train$BldgType)
factorLevel$BldgType
factorLevel$BldgType[c(2,3,5)] <- c("2fmCon","Duplex","Twnhs")
unique(house_train$Exterior2nd)
factorLevel$Exterior2nd
factorLevel$Exterior2nd[c(17,6,3)] <- c("Wd Shng","CmentBd","Brk Cmn")
## Get levels that only appear in the dataset
for (varname in names(factorLevel)) {
factorLevel[[varname]] <- intersect(factorLevel[[varname]],
unique(house_train[[varname]]))
}
## Re-run the previous cell to double check
## convert column datatype to numeric / factor
## On training dataset
for (varname in names(house_train)[-1]) {
if (varname %in% names(factorLevel)) {
house_train[[varname]] <- factor(house_train[[varname]],
levels = factorLevel[[varname]])
} else {
house_train[[varname]] <- as.numeric(house_train[[varname]])
}
}
## On testing dataset
for (varname in names(house_test)[-1]) {
if (varname %in% names(factorLevel)) {
house_test[[varname]] <- factor(house_test[[varname]],
levels = factorLevel[[varname]])
} else {
house_test[[varname]] <- as.numeric(house_test[[varname]])
}
}
#Convert OverallQual from Factor to Numeric
#house_train$OverallQual=as.numeric(as.character(house_train$OverallQual))
#house_test$OverallQual=as.numeric(as.character(house_test$OverallQual))
names(house_train)
shortlis=c('MSZoning','Neighborhood','HouseStyle','OverallQual','YearBuilt',
'ExterQual','Foundation','BsmtQual','X1stFlrSF','X2ndFlrSF','GrLivArea',
'FullBath','TotRmsAbvGrd','GarageFinish','GarageCars','GarageArea',
'PavedDrive','SaleType','SaleCondition')
house_train=house_train[,c(shortlis,'SalePrice')]
house_test=house_test[,shortlis]
View(house_train)
View(house_test)
house_train$Id <- NULL
rownames(house_test) <- house_test$Id
house_test$Id <- NULL
save(house_train, house_test, file = "./house_loaded.RData")
load('house_loaded.RData')
ggplot(house_train, aes(x=OverallQual,y=log(SalePrice)))+geom_violin()+geom_boxplot(width=.1)
house_train%>%group_by(OverallQual)%>%summarise(sd,min,max,median)
house_train%>%group_by(OverallQual)%>%summarise(std,min,max,median)
house_train%>%group_by(OverallQual)%>%summarise(sdev,min,max,median)
house_train%>%group_by(OverallQual)%>%summarise(sd(SalePrice),min(SalePrice),max(SalePrice),median(SalePrice))
house_train%>%group_by(OverallQual)%>%summarise(sd(SalePrice),min(SalePrice),max(SalePrice),mean(SalePrice))
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(dplyr)
library(tidyr)
library(reshape2)
data('house_prep_v1.RData')
library(ggplot2)
library(dplyr)
library(tidyr)
library(reshape2)
data('house_prep_v1.RData')
setwd("C:/Users/cmlim/Dropbox/NYC Data Science/Class/Machine Learning Project/chungmeng")
library(ggplot2)
library(dplyr)
library(tidyr)
library(reshape2)
data('house_prep_v1.RData')
library(ggplot2)
library(dplyr)
library(tidyr)
library(reshape2)
load('house_prep_v1.RData')
x=model.matrix(SalePrice~.,house_train)
x
nrow(x)
set.seed(0) #Extract 20% as Test Set
test=sample(x=1:nrow(x),size = round(0.2*nrow(x)))
test
train=(-test)
x.train=x[train,]
x.test=x[test,]
dim(x.train)
dim(x.test)
grid=10^(seq(5,-2,length.out = 100))
grid
x.test
y.train=y[train]
y=house_train$SalePrice
y.train=y[train]
multlin.model = lm(y.train ~ ., data = x.train)
multlin.model = lm(SalePrice~.,house_train)
summary(multlin.model)
View(house_train)
multlin.model = lm(SalePrice~.,house_train[train, ])
summary(multlin.model)
summary(house_train)
class(house_train)
str(house_train)
house_train$SaleType=as.factor(house_train$SaleType)
house_train$SaleCondition=as.factor(house_train$SaleCondition)
str(house_train)
multlin.model = lm(SalePrice~.,house_train[train, ])
summary(multlin.model)
house_train[test, -13]
predict(multlin.model,newdata =house_train[test, -13])
pred.SalePrice=predict(multlin.model,newdata =house_train[test, -13])
View(data.frame(house_train[test,SalePrice], pred.SalePrice))
View(data.frame(house_train[test,'SalePrice'], pred.SalePrice))
plot(x=1:length(test),house_train[test,'SalePrice'])
plot(x=1:length(test),house_train[test,'SalePrice'],col='red')
plot(x=1:length(test),pred.SalePrice)
plot(x=1:length(test),house_train[test,'SalePrice'],col='red')
plot(x=1:length(test),pred.SalePrice)
ggplot()+geom_point(aes(x=1:length(test), y=house_train[test,'SalePrice'], col='r'))
ggplot()+
geom_point(aes(x=1:length(test), y=house_train[test,'SalePrice'], col='r')) +
geom_point(aes(x=1:length(test), y=pred.SalePrice, col='b'))
ggplot()+
geom_point(aes(x=1:length(test), y=house_train[test,'SalePrice'], col='r')) +
geom_point(aes(x=1:length(test), y=pred.SalePrice, col='g'))
ggplot()+
geom_point(aes(x=1:length(test), y=house_train[test,'SalePrice'], col='r')) +
geom_point(aes(x=1:length(test), y=pred.SalePrice, col='greeen'))
ggplot()+
geom_point(aes(x=1:length(test), y=house_train[test,'SalePrice'], col='r')) +
geom_point(aes(x=1:length(test), y=pred.SalePrice, color='green'))
ggplot()+
geom_point(aes(x=1:length(test), y=house_train[test,'SalePrice'], col='r')) +
geom_point(aes(x=1:length(test), y=pred.SalePrice, color='g'))
ggplot()+
geom_histogram(aes(x=house_train[test,'SalePrice']))
ggplot()+
geom_histogram(aes(x=pred.SalePrice))
mean((house_train[test,'SalePrice']-pred.SalePrice)^2)
ggplot()+
geom_histogram(aes(x=(house_train[test,'SalePrice']-pred.SalePrice)))
?RMSE
RMSE=function(x1,x2){
return(sqrt(mean((x1-x2)^2)))
}
RMSE(c(1,3),c(2,5))
sqrt(2.5)
RMSE(c(1,3,1),c(2,5,3))
sqrt(3)
RMSE(log(house_train[test,'SalePrice']),log(pred.SalePrice))
set.seed(0) #Extract 20% as Test Set
test=sample(x=1:nrow(house_train),size = round(0.2*nrow(house_train)))
train=(-test)
multlin.model = lm(log(SalePrice+1)~.,house_train[train, ])
summary(multlin.model)
pred.SalePrice=predict(multlin.model,newdata =house_train[test, -13])
View(data.frame(house_train[test,'SalePrice'], pred.SalePrice))
ggplot()+
geom_point(aes(x=1:length(test), y=house_train[test,'SalePrice'], col='r')) +
geom_point(aes(x=1:length(test), y=pred.SalePrice, color='g'))
ggplot()+
geom_histogram(aes(x=house_train[test,'SalePrice']))
ggplot()+
geom_histogram(aes(x=pred.SalePrice))
mean((house_train[test,'SalePrice']-pred.SalePrice)^2)
ggplot()+
geom_histogram(aes(x=(house_train[test,'SalePrice']-pred.SalePrice)))
#plot(x=1:length(test),house_train[test,'SalePrice'],col='red')
RMSE(log(house_train[test,'SalePrice']+1),pred.SalePrice)
View(data.frame(log(house_train[test,'SalePrice']+1), pred.SalePrice))
set.seed(0) #Extract 20% as Test Set
test=sample(x=1:nrow(house_train),size = round(0.2*nrow(house_train)))
train=(-test)
multlin.model = lm(SalePrice~.,house_train[train, ])
summary(multlin.model)
pred.SalePrice=predict(multlin.model,newdata =house_train[test, -13])
View(data.frame(house_train[test,'SalePrice'], pred.SalePrice))
ggplot()+
geom_point(aes(x=1:length(test), y=house_train[test,'SalePrice'], col='r')) +
geom_point(aes(x=1:length(test), y=pred.SalePrice, color='g'))
ggplot()+
geom_histogram(aes(x=house_train[test,'SalePrice']))
ggplot()+
geom_histogram(aes(x=pred.SalePrice))
mean((house_train[test,'SalePrice']-pred.SalePrice)^2)
ggplot()+
geom_histogram(aes(x=(house_train[test,'SalePrice']-pred.SalePrice)))
#plot(x=1:length(test),house_train[test,'SalePrice'],col='red')
multilin.RMSLE=RMSE(log(house_train[test,'SalePrice']),log(pred.SalePrice))
multilin.RMSLE
ggplot()+
geom_point(aes(y=pred.SalePrice, x=house_train[test,'SalePrice'], col='r')) +
ggplot()+
geom_point(aes(y=pred.SalePrice, x=house_train[test,'SalePrice'], col='r')) #+
## Simple Multi Linear Regression
```{r}
set.seed(0) #Extract 20% as Test Set
test=sample(x=1:nrow(house_train),size = round(0.2*nrow(house_train)))
train=(-test)
multlin.model = lm(SalePrice~.,house_train[train, ])
summary(multlin.model)
pred.SalePrice=predict(multlin.model,newdata =house_train[test, -13])
View(data.frame(house_train[test,'SalePrice'], pred.SalePrice))
ggplot()+
geom_point(aes(y=pred.SalePrice, x=house_train[test,'SalePrice'], col='r')) #+
# ggplot()+
#   geom_histogram(aes(x=house_train[test,'SalePrice']))
# ggplot()+
#   geom_histogram(aes(x=pred.SalePrice))
# mean((house_train[test,'SalePrice']-pred.SalePrice)^2)
# ggplot()+
#   geom_histogram(aes(x=(house_train[test,'SalePrice']-pred.SalePrice)))
#plot(x=1:length(test),house_train[test,'SalePrice'],col='red')
multilin.RMSLE=RMSE(log(house_train[test,'SalePrice']),log(pred.SalePrice))
multilin.RMSLE
set.seed(0) #Extract 20% as Test Set
test=sample(x=1:nrow(house_train),size = round(0.2*nrow(house_train)))
train=(-test)
multlin.model = lm(SalePrice~.,house_train[train, ])
summary(multlin.model)
pred.SalePrice=predict(multlin.model,newdata =house_train[test, -13])
View(data.frame(house_train[test,'SalePrice'], pred.SalePrice))
ggplot()+
geom_point(aes(y=pred.SalePrice, x=house_train[test,'SalePrice'], col='r')) #+
# ggplot()+
#   geom_histogram(aes(x=house_train[test,'SalePrice']))
# ggplot()+
#   geom_histogram(aes(x=pred.SalePrice))
# mean((house_train[test,'SalePrice']-pred.SalePrice)^2)
# ggplot()+
#   geom_histogram(aes(x=(house_train[test,'SalePrice']-pred.SalePrice)))
#plot(x=1:length(test),house_train[test,'SalePrice'],col='red')
multilin.RMSLE=RMSE(log(house_train[test,'SalePrice']),log(pred.SalePrice))
multilin.RMSLE
set.seed(0) #Extract 20% as Test Set
test=sample(x=1:nrow(house_train),size = round(0.2*nrow(house_train)))
train=(-test)
multlin.model = lm(SalePrice~.,house_train[train, ])
summary(multlin.model)
pred.SalePrice=predict(multlin.model,newdata =house_train[test, -13])
prediction_df=data.frame(SalePrice=house_train[test,'SalePrice'], MultiLin=pred.SalePrice)
View(prediction_df)
ggplot()+
geom_point(aes(y=pred.SalePrice, x=house_train[test,'SalePrice'], col='r')) #+
# ggplot()+
#   geom_histogram(aes(x=house_train[test,'SalePrice']))
# ggplot()+
#   geom_histogram(aes(x=pred.SalePrice))
# mean((house_train[test,'SalePrice']-pred.SalePrice)^2)
# ggplot()+
#   geom_histogram(aes(x=(house_train[test,'SalePrice']-pred.SalePrice)))
#plot(x=1:length(test),house_train[test,'SalePrice'],col='red')
multilin.RMSLE=RMSE(log(house_train[test,'SalePrice']),log(pred.SalePrice))
multilin.RMSLE
ggplot()+
geom_point(aes(y=pred.SalePrice, x=house_train[test,'SalePrice'], col='r'))
multlin.model$coefficients
multlin.model$residuals
vif(multlin.model)
library(car)
library(caret)
vif(multlin.model)
summary(multlin.model)
influencePlot(multlin.model)
set.seed(0) #Extract 20% as Test Set
test=sample(x=1:nrow(house_train),size = round(0.2*nrow(house_train)))
train=(-test)
multlin.model = lm(SalePrice~.,house_train[train, ])
summary(multlin.model)
#influencePlot(multlin.model)
pred.SalePrice=predict(multlin.model,newdata =house_train[test, -13])
prediction_df=data.frame(SalePrice=house_train[test,'SalePrice'], MultiLin=pred.SalePrice)
View(prediction_df)
ggplot()+
geom_point(aes(y=pred.SalePrice, x=house_train[test,'SalePrice'], col='r')) #+
# ggplot()+
#   geom_histogram(aes(x=house_train[test,'SalePrice']))
# ggplot()+
#   geom_histogram(aes(x=pred.SalePrice))
# mean((house_train[test,'SalePrice']-pred.SalePrice)^2)
# ggplot()+
#   geom_histogram(aes(x=(house_train[test,'SalePrice']-pred.SalePrice)))
#plot(x=1:length(test),house_train[test,'SalePrice'],col='red')
multilin.RMSLE=RMSE(log(house_train[test,'SalePrice']),log(pred.SalePrice))
multilin.RMSLE
train(SalePrice ~., data=house_train[train,],
method="glmStepAIC", k=2,
trControl=trainControl(method="none"))
trained=train(SalePrice ~., data=house_train[train,],
method="glmStepAIC", k=2,
trControl=trainControl(method="none"))
summary(trained)
x=model.matrix(SalePrice~.,house_train)[-1] #Discard Intercept
y=house_train$SalePrice
set.seed(0) #Extract 20% as Test Set
#x.train=x[train,]
#y.train=y[train]
#x.test=x[test,]
#y.test=y[test]
grid=10^(seq(5,-2,length.out = 100))
cv.ridge.model = cv.glmnet(x[train, ], y[train],
lambda = grid, alpha = 0, nfolds = 10)
library(glmnet)
x=model.matrix(SalePrice~.,house_train)[-1] #Discard Intercept
y=house_train$SalePrice
set.seed(0) #Extract 20% as Test Set
#x.train=x[train,]
#y.train=y[train]
#x.test=x[test,]
#y.test=y[test]
grid=10^(seq(5,-2,length.out = 100))
cv.ridge.model = cv.glmnet(x[train, ], y[train],
lambda = grid, alpha = 0, nfolds = 10)
x[train, ]
dim(x)
x
x=model.matrix(SalePrice~.,house_train)[-1]
x
x=model.matrix(SalePrice~.,house_train)[,-1] #Discard Intercept
y=house_train$SalePrice
#set.seed(0) #Extract 20% as Test Set
#x.train=x[train,]
#y.train=y[train]
#x.test=x[test,]
#y.test=y[test]
grid=10^(seq(5,-2,length.out = 100))
cv.ridge.model = cv.glmnet(x[train, ], y[train],
lambda = grid, alpha = 0, nfolds = 10)
plot(cv.ridge.out, main = "Ridge Regression\n")
x=model.matrix(SalePrice~.,house_train)[,-1] #Discard Intercept
y=house_train$SalePrice
#set.seed(0) #Extract 20% as Test Set
#x.train=x[train,]
#y.train=y[train]
#x.test=x[test,]
#y.test=y[test]
grid=10^(seq(5,-2,length.out = 100))
cv.ridge.model = cv.glmnet(x[train, ], y[train],
lambda = grid, alpha = 0, nfolds = 10)
plot(cv.ridge.model, main = "Ridge Regression\n")
x=model.matrix(SalePrice~.,house_train)[,-1] #Discard Intercept
y=house_train$SalePrice
#set.seed(0) #Extract 20% as Test Set
#x.train=x[train,]
#y.train=y[train]
#x.test=x[test,]
#y.test=y[test]
grid=10^(seq(7,-1,length.out = 100))
cv.ridge.model = cv.glmnet(x[train, ], y[train],
lambda = grid, alpha = 0, nfolds = 10)
plot(cv.ridge.model, main = "Ridge Regression\n")
coef(cv.ridge.model)
bestlambda.cv.ridge = cv.ridge.model$lambda.min
bestlambda.cv.ridge
log(bestlambda.cv.ridge)
x=model.matrix(SalePrice~.,house_train)[,-1] #Discard Intercept
y=house_train$SalePrice
grid=10^(seq(7,-1,length.out = 100))
cv.ridge.model = cv.glmnet(x[train, ], y[train],
lambda = grid, alpha = 0, nfolds = 10)
plot(cv.ridge.model, main = "Ridge Regression\n")
coef(cv.ridge.model)
bestlambda.cv.ridge = cv.ridge.model$lambda.min
bestlambda.cv.ridge
log(bestlambda.cv.ridge)
x=model.matrix(SalePrice~.,house_train)[,-1] #Discard Intercept
y=house_train$SalePrice
grid=10^(seq(7,-1,length.out = 100))
#First Run 10-Folds CV to Determine Best Lambda
cv.ridge.model = cv.glmnet(x[train, ], y[train],
lambda = grid, alpha = 0, nfolds = 10)
plot(cv.ridge.model, main = "Ridge Regression\n")
coef(cv.ridge.model)
bestlambda.cv.ridge = cv.ridge.model$lambda.min
bestlambda.cv.ridge
log(bestlambda.cv.ridge)
#Let's create the GLM Model with Best Lambda
ridge.model = glmnet(x[train, ], y[train], alpha = 0, lambda = grid)
#What is the test MSE associated with this best value of lambda?
pred.ridge = predict(ridge.model, s = bestlambda.cv.ridge, newx = x[test, ])
mean((pred.ridge - y.test)^2)
x=model.matrix(SalePrice~.,house_train)[,-1] #Discard Intercept
y=house_train$SalePrice
grid=10^(seq(7,-1,length.out = 100))
#First Run 10-Folds CV to Determine Best Lambda
cv.ridge.model = cv.glmnet(x[train, ], y[train],
lambda = grid, alpha = 0, nfolds = 10)
plot(cv.ridge.model, main = "Ridge Regression\n")
coef(cv.ridge.model)
bestlambda.cv.ridge = cv.ridge.model$lambda.min
bestlambda.cv.ridge
log(bestlambda.cv.ridge)
#Let's create the GLM Model with Best Lambda
ridge.model = glmnet(x[train, ], y[train], alpha = 0, lambda = grid)
#What is the test MSE associated with this best value of lambda?
pred.ridge = predict(ridge.model, s = bestlambda.cv.ridge, newx = x[test, ])
mean((pred.ridge - y[test])^2)
RMSE(log(pred.ridge),log(y[test]))
cbind(prediction_df,pred.ridge)
cbind(prediction_df,CV_Ridge=pred.ridge)
data.frame(prediction_df,CV_Ridge=pred.ridge)
data.frame(prediction_df,CV_Ridge=as.numeric(pred.ridge))
prediction_df=data.frame(prediction_df,CV_Ridge=as.numeric(pred.ridge))
head(prediction_df)
prediction_df=data.frame(prediction_df,RidgeCV=as.numeric(pred.ridge))
head(prediction_df)
